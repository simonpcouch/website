{
  "hash": "860a1934dfc1255e05354bbc0f9469b4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Postprocessing is coming to tidymodels\"\ndate: '2024-10-16'\ntags:\n  - rstats\n  - tidymodels\n  - postprocessing\nsubtitle: \"The tidymodels team has been hard at work on postprocessing, a set of\n    features to adjust model predictions. The functionality includes a new\n    package as well as changes across the framework.\"\nimage: featured.png\nsummary: ''\n---\n\n\n\n\n\n:::callout-note\nThis is a cross-post of [a post of mine](https://www.tidyverse.org/blog/2024/10/postprocessing-preview/) on the tidyverse blog.\n:::\n\nWe're bristling with elation to share about a set of upcoming features for postprocessing with tidymodels. Postprocessors refine predictions outputted from machine learning models to improve predictive performance or better satisfy distributional limitations. The developmental versions of many tidymodels core packages include changes to support postprocessors, and we're ready to share about our work and hear the community's thoughts on our progress so far.\n\nPostprocessing support with tidymodels hasn't yet made it to CRAN, but you can install the needed versions of tidymodels packages with the following code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npak::pak(\n  paste0(\n    \"tidymodels/\",\n    c(\"tune\", \"workflows\", \"rsample\", \"tailor\")\n  )\n)\n```\n:::\n\n\n\nNow, we load packages with those developmental versions installed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(probably)\nlibrary(tailor)\n```\n:::\n\n\n\nExisting tidymodels users might have spotted something funky already; who is this tailor character?\n\n## Meet tailorðŸ‘‹\n\nThe tailor package introduces tailor objects, which compose iterative adjustments to model predictions. tailor is to postprocessing as recipes is to preprocessing; applying your mental model of recipes to tailor should get you a good bit of the way there.\n\n| Tool | Applied to\\... | Initialize with\\... | Composes\\... | Train with\\... | Predict with\\... |\n|------------|------------|------------|------------|------------|------------|\n| recipes | Training data | `recipe()` | `step_*()`s | `prep()` | `bake()` |\n| tailor | Model predictions | `tailor()` | `adjust_*()`ments | `fit()` | `predict()` |\n\nFirst, users can initialize a tailor object with `tailor()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntailor()\n## \n## â”€â”€ tailor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## A postprocessor with 0 adjustments.\n```\n:::\n\n\n\nTailors compose \"adjustments,\" analogous to steps from the recipes package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntailor() %>%\n  adjust_probability_threshold(threshold = .7)\n## \n## â”€â”€ tailor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## A binary postprocessor with 1 adjustment:\n## \n## â€¢ Adjust probability threshold to 0.7.\n```\n:::\n\n\n\nAs an example, we'll apply this tailor to the `two_class_example` data made available after loading tidymodels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(two_class_example)\n##    truth      Class1       Class2 predicted\n## 1 Class2 0.003589243 0.9964107574    Class2\n## 2 Class1 0.678621054 0.3213789460    Class1\n## 3 Class2 0.110893522 0.8891064779    Class2\n## 4 Class1 0.735161703 0.2648382969    Class1\n## 5 Class2 0.016239960 0.9837600397    Class2\n## 6 Class1 0.999275071 0.0007249286    Class1\n```\n:::\n\n\n\nThis data gives the true value of an outcome variable `truth` as well as predicted probabilities (`Class1` and `Class2`). The hard class predictions, in `predicted`, are `\"Class1\"` if the probability assigned to `\"Class1\"` is above .5, and `\"Class2\"` otherwise.\n\nThe model predicts `\"Class1\"` more often than it does `\"Class2\"`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwo_class_example %>% count(predicted)\n##   predicted   n\n## 1    Class1 277\n## 2    Class2 223\n```\n:::\n\n\n\nIf we wanted the model to predict `\"Class2\"` more often, we could increase the probability threshold assigned to `\"Class1\"` above which the hard class prediction will be `\"Class1\"`. In the tailor package, this adjustment is implemented in `adjust_probability_threshold()`, which can be situated in a tailor object.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntlr <-\n  tailor() %>%\n  adjust_probability_threshold(threshold = .7)\n\ntlr\n## \n## â”€â”€ tailor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## A binary postprocessor with 1 adjustment:\n## \n## â€¢ Adjust probability threshold to 0.7.\n```\n:::\n\n\n\ntailors must be fitted before they can predict on new data. For adjustments like `adjust_probability_threshold()`, there's no training that actually happens at the `fit()` step besides recording the name and type of relevant variables. For other adjustments, like numeric calibration with `adjust_numeric_calibration()`, parameters are actually estimated at the `fit()` stage and separate data should be used to train the postprocessor and evaluate its performance. More on this in [Tailors in context](#tailors-in-context).\n\nIn this case, though, we can `fit()` on the whole dataset. The resulting object is still a tailor, but is now flagged as trained.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntlr_trained <- fit(\n  tlr,\n  two_class_example,\n  outcome = truth,\n  estimate = predicted,\n  probabilities = c(Class1, Class2)\n)\n\ntlr_trained\n## \n## â”€â”€ tailor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## A binary postprocessor with 1 adjustment:\n## \n## â€¢ Adjust probability threshold to 0.7. [trained]\n```\n:::\n\n\n\nWhen used with a model [workflow](https://workflows.tidymodels.org) via [`add_tailor()`](https://workflows.tidymodels.org/dev/reference/add_tailor.html), the arguments to `fit()` a tailor will be set automatically. Generally, as in recipes, we recommend that users add tailors to model workflows for training and prediction rather than using them standalone for greater ease of use and to prevent data leakage, but tailors are totally functional by themselves, too.\n\nNow, when passed new data, the trained tailor will determine the outputted class based on whether the probability assigned to the level `\"Class1\"` is above `.7`, resulting in more predictions of `\"Class2\"` than before.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(tlr_trained, two_class_example) %>% count(predicted)\n## # A tibble: 2 Ã— 2\n##   predicted     n\n##   <fct>     <int>\n## 1 Class1      236\n## 2 Class2      264\n```\n:::\n\n\n\nChanging the probability threshold is one of many possible adjustments available in tailor.\n\n-   For probabilities: [calibration](https://tailor.tidymodels.org/reference/adjust_probability_calibration.html)\n-   For transformation of probabilities to hard class predictions: [thresholds](https://tailor.tidymodels.org/reference/adjust_probability_threshold.html), [equivocal zones](https://tailor.tidymodels.org/reference/adjust_equivocal_zone.html)\n-   For numeric outcomes: [calibration](https://tailor.tidymodels.org/reference/adjust_numeric_calibration.html), [range](https://tailor.tidymodels.org/reference/adjust_numeric_range.html)\n\nSupport for tailors is now plumbed through workflows (via [`add_tailor()`](https://workflows.tidymodels.org/dev/reference/add_tailor.html)) and tune, and rsample includes a set of infrastructural changes to prevent data leakage behind the scenes. That said, we haven't yet implemented support for tuning parameters in tailors, but we plan to implement that before this functionality heads to CRAN.\n\n## Tailors in context\n\nAs an example, let's model a study of food delivery times in minutes (i.e., the time from the initial order to receiving the food) for a single restaurant. The `deliveries` data is available upon loading the tidymodels meta-package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(deliveries)\n\n# split into training and testing sets\nset.seed(1)\ndelivery_split <- initial_split(deliveries)\ndelivery_train <- training(delivery_split)\ndelivery_test  <- testing(delivery_split)\n\n# resample the training set using 10-fold cross-validation\nset.seed(1)\ndelivery_folds <- vfold_cv(delivery_train)\n\n# print out the training set\ndelivery_train\n## # A tibble: 7,509 Ã— 31\n##    time_to_delivery  hour day   distance item_01 item_02 item_03 item_04 item_05\n##               <dbl> <dbl> <fct>    <dbl>   <int>   <int>   <int>   <int>   <int>\n##  1             21.2  16.1 Tue       3.02       0       0       0       0       0\n##  2             17.9  12.4 Sun       3.37       0       0       0       0       0\n##  3             22.4  14.2 Fri       2.59       0       0       0       0       0\n##  4             30.9  19.1 Sat       2.77       0       0       0       0       0\n##  5             30.1  16.5 Fri       2.05       0       0       0       1       0\n##  6             35.3  14.7 Sat       4.57       0       0       2       1       1\n##  7             13.1  11.5 Sat       2.09       0       0       0       0       0\n##  8             18.3  13.4 Tue       2.35       0       2       1       0       0\n##  9             25.2  20.5 Sat       2.43       0       0       0       1       0\n## 10             30.7  16.7 Fri       2.24       0       0       0       1       0\n## # â„¹ 7,499 more rows\n## # â„¹ 22 more variables: item_06 <int>, item_07 <int>, item_08 <int>,\n## #   item_09 <int>, item_10 <int>, item_11 <int>, item_12 <int>, item_13 <int>,\n## #   item_14 <int>, item_15 <int>, item_16 <int>, item_17 <int>, item_18 <int>,\n## #   item_19 <int>, item_20 <int>, item_21 <int>, item_22 <int>, item_23 <int>,\n## #   item_24 <int>, item_25 <int>, item_26 <int>, item_27 <int>\n```\n:::\n\n\n\nLet's deliberately define a regression model that has poor predicted values: a boosted tree with only three ensemble members.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelivery_wflow <-\n  workflow() %>%\n  add_formula(time_to_delivery ~ .) %>%\n  add_model(boost_tree(mode = \"regression\", trees = 3))\n```\n:::\n\n\n\nEvaluating against resamples:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\ndelivery_res <- \n  fit_resamples(\n    delivery_wflow, \n    delivery_folds, \n    control = control_resamples(save_pred = TRUE)\n  )\n```\n:::\n\n\n\nThe $R^2$ looks quite strong!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(delivery_res)\n## # A tibble: 2 Ã— 6\n##   .metric .estimator  mean     n std_err .config             \n##   <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n## 1 rmse    standard   9.52     10 0.0533  Preprocessor1_Model1\n## 2 rsq     standard   0.853    10 0.00357 Preprocessor1_Model1\n```\n:::\n\n\n\nLet's take a closer look at the predictions, though. How well are they calibrated? We can use the `cal_plot_regression()` helper from the probably package to put together a quick diagnostic plot.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncollect_predictions(delivery_res) %>%\n  cal_plot_regression(truth = time_to_delivery, estimate = .pred)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/predictions-bad-boost-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\nOoof.\n\nIn comes tailor! Numeric calibration can help address the correlated errors here. We can add a tailor to our existing workflow to \"bump up\" predictions towards their true value.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelivery_wflow_improved <-\n  delivery_wflow %>%\n  add_tailor(tailor() %>% adjust_numeric_calibration())\n```\n:::\n\n\n\nThe resampling code looks the same from here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\ndelivery_res_improved <- \n  fit_resamples(\n    delivery_wflow_improved, \n    delivery_folds, \n    control = control_resamples(save_pred = TRUE)\n  )\n```\n:::\n\n\n\nChecking out the same plot reveals a much better fit!\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncollect_predictions(delivery_res_improved) %>%\n  cal_plot_regression(truth = time_to_delivery, estimate = .pred)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/predictions-better-boost-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\nThere's actually some tricky data leakage prevention happening under the hood here. When you add tailors to workflow and fit them with tune, this is all taken care of for you. If you're interested in using tailors outside of that context, check out [this documentation section](https://workflows.tidymodels.org/dev/reference/add_tailor.html#data-usage) in `add_tailor()`.\n\n## What's to come\n\nWe're excited about how this work is shaping up and would love to hear yall's thoughts on what we've brought together so far. Please do comment on our social media posts about this blog entry or leave issues on the [tailor GitHub repository](https://github.com/tidymodels/tailor) and let us know what you think!\n\nBefore these changes head out to CRAN, we'll also be implementing tuning functionality for postprocessors. You'll be able to tag arguments like `adjust_probability_threshold(threshold)` or `adjust_probability_calibration(method)` with `tune()` to optimize across several values. Besides that, post-processing with tidymodels should \"just work\" on the developmental versions of our packages---let us know if you come across anything wonky.\n\n## Acknowledgements\n\nPostprocessing support has been a longstanding feature request across many of our repositories; we're grateful for the community discussions there for shaping this work. Additionally, we thank Ryan Tibshirani and Daniel McDonald for fruitful discussions on how we might scope these features.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
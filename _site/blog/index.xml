<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Simon P. Couch</title>
<link>https://simonpcouch.com/blog/</link>
<atom:link href="https://simonpcouch.com/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>A data science blog</description>
<generator>quarto-1.6.40</generator>
<lastBuildDate>Fri, 18 Apr 2025 05:00:00 GMT</lastBuildDate>
<item>
  <title>Evaluating o3 and o4-mini on R coding performance</title>
  <link>https://simonpcouch.com/blog/2025-04-18-o3-o4-mini/</link>
  <description><![CDATA[ 48 hours after the drop of the GPT 4.1 series of models, a trio of non-reasoning models focused on “real-world developer needs,” OpenAI dropped another set of models, o3 and o4-mini. These two models are the latest generation of thinking models from OpenAI, and they form the backbone of <a href="https://github.com/openai/codex">Codex</a>, a new Claude Code competitor from OpenAI. In short, OpenAI wants market share among developers. ]]></description>
  <guid>https://simonpcouch.com/blog/2025-04-18-o3-o4-mini/</guid>
  <pubDate>Fri, 18 Apr 2025 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-04-18-o3-o4-mini/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>How good are the GPT 4.1 models at writing R code?</title>
  <link>https://simonpcouch.com/blog/2025-04-15-gpt-4-1/</link>
  <description><![CDATA[ Yesterday, OpenAI dropped <a href="https://openai.com/index/gpt-4-1/">a new series of models</a> called GPT 4.1, 4.1 mini, and GPT 4.1 nano. This line from their release post, specifically, caught my eye: ]]></description>
  <guid>https://simonpcouch.com/blog/2025-04-15-gpt-4-1/</guid>
  <pubDate>Tue, 15 Apr 2025 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-04-15-gpt-4-1/featured.png" medium="image" type="image/png" height="142" width="144"/>
</item>
<item>
  <title>Introducing chores</title>
  <link>https://simonpcouch.com/blog/2025-04-11-chores/</link>
  <description><![CDATA[ The following is a cross-post of a post I put together for the Posit Blog; you can read that post <a href="https://posit.co/blog/introducing-chores/">here</a>. ]]></description>
  <guid>https://simonpcouch.com/blog/2025-04-11-chores/</guid>
  <pubDate>Fri, 11 Apr 2025 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-04-11-chores/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>How Good Is Gemini 2.5 Pro at Writing R Code?</title>
  <link>https://simonpcouch.com/blog/2025-04-01-gemini-2-5-pro/</link>
  <description><![CDATA[ Since Gemini 2.5 Pro Experimental’s <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/">release</a> last week, I’ve been seeing a <a href="https://thezvi.substack.com/p/gemini-25-is-the-new-sota?utm_source=post-email-title&amp;publication_id=573100&amp;post_id=160014258&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=21np6y&amp;triedRedirect=true&amp;utm_medium=email">lot</a> <a href="https://simonwillison.net/2025/Mar/25/gemini/">of</a> <a href="https://www.youtube.com/watch?v=A0V4km88tFc&amp;t=700s">hype</a> claiming that the model is the new state of the art. I’ve been wondering—how good is this model at writing R code? ]]></description>
  <guid>https://simonpcouch.com/blog/2025-04-01-gemini-2-5-pro/</guid>
  <pubDate>Wed, 02 Apr 2025 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-04-01-gemini-2-5-pro/featured.png" medium="image" type="image/png" height="147" width="144"/>
</item>
<item>
  <title>How I’m Using Claude Code to Develop R Packages</title>
  <link>https://simonpcouch.com/blog/2025-03-26-claude-code/</link>
  <description><![CDATA[ Since the release of <a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview">Claude Code</a> a few weeks ago, I’ve been experimenting with using the tool to develop R packages. I’ve come to really appreciate it as part of my LLM toolkit, but it’s definitely taken a bit of getting used to. ]]></description>
  <guid>https://simonpcouch.com/blog/2025-03-26-claude-code/</guid>
  <pubDate>Wed, 26 Mar 2025 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-03-26-claude-code/featured.png" medium="image" type="image/png" height="143" width="144"/>
</item>
<item>
  <title>Exploring Biases in GPT-4o, Claude, and Qwen2.5 Judgements</title>
  <link>https://simonpcouch.com/blog/2025-01-30-llm-biases/</link>
  <description><![CDATA[ I’ve been spending some time recently learning about LLMs evaluating output from LLMs, or as its referred to in the literature, “LLM-as-a-judge.” That is, after asking a question to an LLM and receiving an answer, both the question and answer are provided to another language model and that model is asked to somehow judge whether the provided response was satisfactory. ]]></description>
  <guid>https://simonpcouch.com/blog/2025-01-30-llm-biases/</guid>
  <pubDate>Thu, 30 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2025-01-30-llm-biases/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Which names that are also names of countries are most common?</title>
  <link>https://simonpcouch.com/blog/2024-12-23-names/</link>
  <description><![CDATA[ Sitting around the living room over the weekend, someone asked “Which names that are also names of countries are most common?” We all gave guesses, and then I gave in to the urge to reach for my laptop and generate an answer that was authoritative enough for our purposes. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-12-23-names/</guid>
  <pubDate>Mon, 23 Dec 2024 06:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-12-23-names/featured.png" medium="image" type="image/png" height="134" width="144"/>
</item>
<item>
  <title>Announcing a new book</title>
  <link>https://simonpcouch.com/blog/2024-10-29-book/</link>
  <description><![CDATA[ Over the last couple years, I’ve spent quite a bit of time focused on making tidymodels code run as fast as possible. Throughout, I’ve written about this work a good bit on this blog<sup>1</sup> and the tidyverse blog<sup>2</sup>. Early this year, I had the idea that maybe I ought to compile many of those learnings together in a book, focused on helping tidymodels users reduce the computational time needed to develop machine learning models without sacrificing predictive performance. I wrote portions of a couple chapters over the course of a couple weeks, and then mostly set the book aside for many months. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-10-29-book/</guid>
  <pubDate>Tue, 29 Oct 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-10-29-book/featured.png" medium="image" type="image/png" height="140" width="144"/>
</item>
<item>
  <title>Postprocessing is coming to tidymodels</title>
  <link>https://simonpcouch.com/blog/2024-10-16-postprocessing/</link>
  <description><![CDATA[ This is a cross-post of <a href="https://www.tidyverse.org/blog/2024/10/postprocessing-preview/">a post of mine</a> on the tidyverse blog. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-10-16-postprocessing/</guid>
  <pubDate>Wed, 16 Oct 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-10-16-postprocessing/featured.png" medium="image" type="image/png" height="130" width="144"/>
</item>
<item>
  <title>A new package for profiling parallel R code</title>
  <link>https://simonpcouch.com/blog/2024-07-15-syrup/</link>
  <description><![CDATA[ I’ve found that the following pattern looms large in content about parallel processing with R (including my own): ]]></description>
  <guid>https://simonpcouch.com/blog/2024-07-15-syrup/</guid>
  <pubDate>Mon, 15 Jul 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-07-15-syrup/featured.png" medium="image" type="image/png" height="148" width="144"/>
</item>
<item>
  <title>How to best parallelize boosted tree model fits with tidymodels</title>
  <link>https://simonpcouch.com/blog/2024-05-13-parallel/</link>
  <description><![CDATA[ The <a href="https://xgboost.readthedocs.io/">XGBoost</a> and <a href="https://lightgbm.readthedocs.io/en/stable/">LightGBM</a> modeling engines both enable distributing the computations needed to train a single boosted tree model across several CPU cores. Similarly, the <a href="https://tidymodels.org">tidymodels framework</a> enables distributing model fits across cores. The natural question, then, is whether tidymodels users ought to make use of the engine’s parallelism implementation, tidymodels’ implementation, or both at the same time. This blog post is a scrappy attempt at finding which of those approaches will lead to the smallest elapsed time when fitting many models. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-05-13-parallel/</guid>
  <pubDate>Mon, 13 May 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-05-13-parallel/featured.png" medium="image" type="image/png" height="145" width="144"/>
</item>
<item>
  <title>Measuring elapsed time to fit with tidymodels</title>
  <link>https://simonpcouch.com/blog/2024-04-08-fit-time/</link>
  <description><![CDATA[ <strong>tl;dr</strong>: The development versions of tidymodels packages include methods for a <a href="https://workflows.tidymodels.org/dev/reference/extract-workflow.html">new extract function</a>, <code>extract_fit_time()</code>, that returns the time required to train a workflow. Pass <code>extract_fit_time()</code> as a control option while tuning and run <code>collect_extracts()</code> to see training times for resampled workflows. In this example, we can identify a modeling workflow that trains more than 10x faster than the most performant model with very little decrease in predictive performance. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-04-08-fit-time/</guid>
  <pubDate>Mon, 08 Apr 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-04-08-fit-time/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Run an Oracle Database with Docker Desktop on ARM (M1, M2, M3) MacOS</title>
  <link>https://simonpcouch.com/blog/2024-03-14-oracle/</link>
  <description><![CDATA[ I recently sunk a few days into getting an Oracle database deployed on MacOS with an M1 chip in a docker container via Docker Desktop. The few solutions that I found recommended using the Docker Desktop alternative Colima and/or using publicly available, community-contributed images; I had various troubles getting these solutions to work, and found myself missing the bells and whistles of Docker Desktop along the way. This morning, I finally got this database deployed by building the image myself from the official Oracle source, in Docker Desktop rather than Colima, and thought it’d be worth writing up how I did so, especially given the countless GitHub issue comments, StackOverflow posts, and forum discussion I came across from others in my situation. ]]></description>
  <guid>https://simonpcouch.com/blog/2024-03-14-oracle/</guid>
  <pubDate>Thu, 14 Mar 2024 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2024-03-14-oracle/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Analyzing my own music listening data with R and the tidyverse (2023)</title>
  <link>https://simonpcouch.com/blog/2023-11-30-listening-2023/</link>
  <description><![CDATA[ Aside from exchanging playlists with my partner every once in a while, I’m not much of a Spotify user. Around this time every year, though, all of my friends start posting their Spotify Wrapped, and I get jealous, as the platform that I listen to music on doesn’t have anything like it. Of course, though, it collects data about me (it’s 2023!); <a href="https://www.simonpcouch.com/blog/2022-12-01-listening-2022/">last year</a>, I got to wondering whether I could make a lo-fi knockoff of wrapped using R, the tidyverse, and the data that I have access to. You already know: ]]></description>
  <guid>https://simonpcouch.com/blog/2023-11-30-listening-2023/</guid>
  <pubDate>Thu, 30 Nov 2023 06:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-11-30-listening-2023/featured.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>Predicting flight delays with tidymodels🛩</title>
  <link>https://simonpcouch.com/blog/2023-11-28-flights/</link>
  <description><![CDATA[ <em>Last week, I virtually dropped by University of Wisconsin-Madison for a webinar on tidymodels. Heading into the holidays, I thought a fun example problem might be to try and predict flight delays using flights data from Madison’s airport. This is a very, very difficult modeling problem, and the results aren’t very impressive, but it’s a fun one nonetheless.</em> ]]></description>
  <guid>https://simonpcouch.com/blog/2023-11-28-flights/</guid>
  <pubDate>Tue, 28 Nov 2023 06:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-11-28-flights/featured.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Quarto!</title>
  <link>https://simonpcouch.com/blog/2023-10-24-quarto-site/</link>
  <description><![CDATA[ When I was in college, a coworker at one of my jobs did web development gigs on the side. His personal website was a super slick single-page site, built with Flask. I had no idea how it worked, but I really liked it, so I asked if it was okay to fork his repository and took that site on as my own. Editing the site was painful, and I borked it at least hourly whenever I worked on it. It mostly functioned like a high-gloss CV, and didn’t have any sort of blogging component. It looked something like this: ]]></description>
  <guid>https://simonpcouch.com/blog/2023-10-24-quarto-site/</guid>
  <pubDate>Tue, 24 Oct 2023 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-10-24-quarto-site/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Down the submodels rabbit hole with tidymodels</title>
  <link>https://simonpcouch.com/blog/2023-10-11-submodels-rabbit-hole/</link>
  <description><![CDATA[ A familiar pastime—plotting <code>mtcars</code>: ]]></description>
  <guid>https://simonpcouch.com/blog/2023-10-11-submodels-rabbit-hole/</guid>
  <pubDate>Wed, 11 Oct 2023 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-10-11-submodels-rabbit-hole/featured.png" medium="image" type="image/png" height="131" width="144"/>
</item>
<item>
  <title>Hiking the 2023 John Muir Trail / Nüümü Poyo</title>
  <link>https://simonpcouch.com/blog/2023-09-01-jmt-2023/</link>
  <description><![CDATA[ The John Muir Trail (JMT) is a backpacking trail through California’s Sierra Nevada. For folks heading northbound, the trail begins at the top of Mt. Whitney—the tallest mountain in the contiguous US—ascending 8 mountain passes over 214 miles to Yosemite Valley. The JMT’s route traces portions of Nüümü Poyo, or the People’s Trail: historically significant trade routes maintained by people indigenous to what is now California. ]]></description>
  <guid>https://simonpcouch.com/blog/2023-09-01-jmt-2023/</guid>
  <pubDate>Fri, 01 Sep 2023 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-09-01-jmt-2023/featured.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Optimizing model parameters faster with tidymodels</title>
  <link>https://simonpcouch.com/blog/2023-08-04-parallel-racing/</link>
  <description><![CDATA[ Especially for large amounts of data or large grids of parameters, the time and resources needed to tune statistical models can quickly become a barrier to getting machine learning models deployed. Many examples online demonstrating how to tune hyperparameters with tidymodels use <code>tune_grid()</code> on one CPU core. Making use of parallel processing and using a near-drop-in replacement for <code>tune_grid()</code> can speed up hyperparameter tuning by 20-30x! ]]></description>
  <guid>https://simonpcouch.com/blog/2023-08-04-parallel-racing/</guid>
  <pubDate>Fri, 04 Aug 2023 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-08-04-parallel-racing/featured.png" medium="image" type="image/png" height="141" width="144"/>
</item>
<item>
  <title>Moving On From Baltimore</title>
  <link>https://simonpcouch.com/blog/2023-07-28-moving-on-s23/</link>
  <description><![CDATA[ 2 years ago, I sent out <a href="https://www.simonpcouch.com/blog/whats-next-s21/">a post</a> around the time I graduated from college. I wrote about my gratitude for my time in Oregon, my excitement to start a PhD program in Biostatistics at Johns Hopkins, and the joy of raising my then-very-young dog, Millie. Soon after, in summer 2021, I made the road trip to Baltimore, MD. ]]></description>
  <guid>https://simonpcouch.com/blog/2023-07-28-moving-on-s23/</guid>
  <pubDate>Fri, 28 Jul 2023 05:00:00 GMT</pubDate>
  <media:content url="https://simonpcouch.com/blog/2023-07-28-moving-on-s23/featured.png" medium="image" type="image/png" height="135" width="144"/>
</item>
</channel>
</rss>
